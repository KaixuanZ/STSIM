{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from test import evaluation\n",
    "from test import PearsonCoeff\n",
    "from utils.dataset import Dataset\n",
    "from utils.parse_config import parse_config\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load config file and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='config/train_STSIM.cfg')\n",
      "{'gpus': '0', 'num_workers': '0', 'model': 'STSIM', 'dataset_dir': 'dataset/jana2012/', 'label_file': 'label.xlsx', 'train_img_folder': 'train', 'valid_img_folder': 'train', 'ref_img_folder': 'original', 'weights_path': 'weights/STSIM/', 'epochs': '1000', 'train_batch_size': '1000', 'valid_batch_size': '1000', 'checkpoint_interval': '25', 'evaluation_interval': '50'}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, default=\"config/train_STSIM.cfg\", help=\"path to data config file\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args)\n",
    "config = parse_config(args.config)\n",
    "print(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if not os.path.isdir(config['weights_path']):\n",
    "    os.mkdir(config['weights_path'])\n",
    "\n",
    "# read training data\n",
    "dataset_dir = config['dataset_dir']\n",
    "label_file = config['label_file']\n",
    "dist_img_folder = config['train_img_folder']\n",
    "train_batch_size = int(config['train_batch_size'])\n",
    "trainset = Dataset(data_dir=dataset_dir, label_file=label_file, dist_folder=dist_img_folder)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# read validation data\n",
    "dataset_dir = config['dataset_dir']\n",
    "dist_img_folder = config['valid_img_folder']\n",
    "valid_batch_size = int(config['valid_batch_size'])\n",
    "validset = Dataset(data_dir=dataset_dir, label_file=label_file, dist_folder=dist_img_folder)\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=valid_batch_size)\n",
    "\n",
    "epochs = int(config['epochs'])\n",
    "evaluation_interval = int(config['evaluation_interval'])\n",
    "checkpoint_interval = int(config['checkpoint_interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights/STSIM/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode for STSIM model\n",
    "mode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training and validation\n",
    "if config['model'] == 'STSIM':\n",
    "    # prepare data\n",
    "    X1_train, X2_train, Y_train, mask_train = next(iter(train_loader))\n",
    "    X1_valid, X2_valid, Y_valid, mask_valid = next(iter(valid_loader))\n",
    "\n",
    "    from steerable.sp3Filters import sp3Filters\n",
    "    from metrics.STSIM import *\n",
    "    m = Metric(sp3Filters, device)\n",
    "    # STSIM-M features\n",
    "    X1_train = m.STSIM_M(X1_train.double().to(device))\n",
    "    X2_train = m.STSIM_M(X2_train.double().to(device))\n",
    "    X1_valid = m.STSIM_M(X1_valid.double().to(device))\n",
    "    X2_valid = m.STSIM_M(X2_valid.double().to(device))\n",
    "    Y_train = Y_train.to(device)\n",
    "    Y_valid = Y_valid.to(device)\n",
    "    mask_train = mask_train.to(device)\n",
    "    mask_valid = mask_valid.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STSIM_M(torch.nn.Module):\n",
    "    def __init__(self, dim ,mode = 0, device=None):\n",
    "        '''\n",
    "        Args:\n",
    "            mode: STSIM-M(0),regression(1)\n",
    "        '''\n",
    "        super(STSIM_M, self).__init__()\n",
    "        \n",
    "        self.device = torch.device('cpu') if device is None else device\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode == 0:\n",
    "            self.linear = nn.Linear(dim[0], dim[1])\n",
    "        elif self.mode == 1:\n",
    "            self.hidden = torch.nn.Linear(dim[0], dim[0])\n",
    "            self.predict = torch.nn.Linear(dim[0], 1)\n",
    "        \n",
    "\n",
    "    def forward(self, X1, X2):\n",
    "        '''\n",
    "        Args:\n",
    "            X1:\n",
    "            X2:\n",
    "        Returns:\n",
    "            pred:\n",
    "        '''\n",
    "        \n",
    "        if len(X1.shape)==4:\n",
    "            # the input are raw images, extract STSIM-M features\n",
    "            from steerable.sp3Filters import sp3Filters\n",
    "            m = Metric(sp3Filters, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                X1 = m.STSIM_M(X1)\n",
    "                X2 = m.STSIM_M(X2)\n",
    "        #pred = F.sigmoid(self.linear(torch.abs(X1-X2)))\t# [N, dim]\n",
    "        if self.mode == 0:\n",
    "            pred = self.linear(torch.abs(X1-X2))\t# [N, dim]\n",
    "            pred = torch.bmm(pred.unsqueeze(1), pred.unsqueeze(-1)).squeeze(-1)\t# inner-prod\n",
    "            return torch.sqrt(pred)\t# [N, 1]\n",
    "        elif self.mode == 1:\n",
    "            pred = F.relu(self.hidden(torch.abs(X1-X2)))     \n",
    "            pred = torch.sigmoid(self.predict(pred)) \n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iter 0 : -0.4712392387451764\n",
      "validation iter 0 : 0.8356456962817272\n",
      "training iter 25 : -0.9385652511049726\n",
      "training iter 50 : -0.947427314133046\n",
      "validation iter 50 : 0.947657211465509\n",
      "training iter 75 : -0.9522346894815872\n",
      "training iter 100 : -0.9566073962561596\n",
      "validation iter 100 : 0.9567888718460205\n",
      "training iter 125 : -0.9612451462370515\n",
      "training iter 150 : -0.965809863867595\n",
      "validation iter 150 : 0.9659896400310242\n",
      "training iter 175 : -0.9702564617980274\n",
      "training iter 200 : -0.974288500891398\n",
      "validation iter 200 : 0.9744284969950675\n",
      "training iter 225 : -0.9772344145779019\n",
      "training iter 250 : -0.9794855846875175\n",
      "validation iter 250 : 0.9795681745633736\n",
      "training iter 275 : -0.9814480343724142\n",
      "training iter 300 : -0.983222735422984\n",
      "validation iter 300 : 0.9832892793733106\n",
      "training iter 325 : -0.9847744233655564\n",
      "training iter 350 : -0.9861154644036958\n",
      "validation iter 350 : 0.9861650035063565\n",
      "training iter 375 : -0.9872432159519893\n",
      "training iter 400 : -0.9881443583178401\n",
      "validation iter 400 : 0.9881766685807696\n",
      "training iter 425 : -0.9888937581012955\n",
      "training iter 450 : -0.9895140125629587\n",
      "validation iter 450 : 0.9894962249035137\n",
      "training iter 475 : -0.9901481760138674\n",
      "training iter 500 : -0.9907043706617309\n",
      "validation iter 500 : 0.990725421659256\n",
      "training iter 525 : -0.991205047560156\n",
      "training iter 550 : -0.9916540717024926\n",
      "validation iter 550 : 0.9916678516588753\n",
      "training iter 575 : -0.9920433308926391\n",
      "training iter 600 : -0.9924120518765832\n",
      "validation iter 600 : 0.992420541002493\n",
      "training iter 625 : -0.9927451707075898\n",
      "training iter 650 : -0.992992907429134\n",
      "validation iter 650 : 0.9930095144109062\n",
      "training iter 675 : -0.9932562083230462\n",
      "training iter 700 : -0.9935318208222688\n",
      "validation iter 700 : 0.9935403622739841\n",
      "training iter 725 : -0.9934734027537754\n",
      "training iter 750 : -0.9938475332176451\n",
      "validation iter 750 : 0.9938861486562651\n",
      "training iter 775 : -0.9940545727376191\n",
      "training iter 800 : -0.99417173393107\n",
      "validation iter 800 : 0.9941311282418972\n",
      "training iter 825 : -0.9942887055158535\n",
      "training iter 850 : -0.9940574677023604\n",
      "validation iter 850 : 0.9943249035627515\n",
      "training iter 875 : -0.9944279760904202\n",
      "training iter 900 : -0.993835069880671\n",
      "validation iter 900 : 0.9941632716072772\n",
      "training iter 925 : -0.9946323657572045\n",
      "training iter 950 : -0.9943692556792477\n",
      "validation iter 950 : 0.9943102772355438\n",
      "training iter 975 : -0.9945780327809128\n"
     ]
    }
   ],
   "source": [
    "# learnable parameters\n",
    "model = STSIM_M([X1_train.shape[1], 10],mode,device).double().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(epochs):\n",
    "    pred = model(X1_train, X2_train)\n",
    "    loss = -PearsonCoeff(pred, Y_train, mask_train)  # min neg ==> max\n",
    "    #loss = torch.mean((pred - Y_train) ** 2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 25 == 0:\n",
    "        print('training iter ' + str(i) + ' :', loss.item())\n",
    "    if i % evaluation_interval == 0:    # validation\n",
    "        pred = model(X1_valid, X2_valid)\n",
    "        val = evaluation(pred, Y_valid, mask_valid)\n",
    "        print('validation iter ' + str(i) + ' :', val)\n",
    "    if i % checkpoint_interval == 0:    # save weights\n",
    "        torch.save(model.state_dict(), os.path.join(config['weights_path'], 'epoch_' + str(i).zfill(4) + '.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from steerable.sp3Filters import sp3Filters\n",
    "from utils.dataset import Dataset\n",
    "from utils.parse_config import parse_config\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def PearsonCoeff(X, Y, mask):\n",
    "    '''\n",
    "    Args:\n",
    "        X: [N, 1] neural prediction for one batch, or [N] some other metric's output\n",
    "        Y: [N] label\n",
    "        mask: [N] indicator of correspondent class, e.g. [0,0,1,1] ,means first two samples are class 0, the rest two samples are class 1\n",
    "    Returns: Borda's rule of pearson coeff between X&Y, the same as using numpy.corrcoef()\n",
    "    '''\n",
    "    coeff = 0\n",
    "    N = set(mask.detach().cpu().numpy())\n",
    "    X = X.squeeze(-1)\n",
    "    for i in N:\n",
    "        X1 = X[mask == i].double()\n",
    "        X1 = X1 - X1.mean()\n",
    "        X2 = Y[mask == i].double()\n",
    "        X2 = X2 - X2.mean()\n",
    "\n",
    "        nom = torch.dot(X1, X2)\n",
    "        denom = torch.sqrt(torch.sum(X1 ** 2) * torch.sum(X2 ** 2))\n",
    "\n",
    "        coeff += torch.abs(nom / (denom + 1e-10))\n",
    "    return coeff / len(N)\n",
    "\n",
    "def evaluation(pred, Y, mask):\n",
    "    return PearsonCoeff(pred, Y, mask).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1000, config='config/test.cfg')\n",
      "{'gpus': '0', 'num_workers': '0', 'model': 'STSIM', 'dataset_dir': 'dataset/jana2012/', 'label_file': 'label.xlsx', 'dist_img_folder': 'test', 'ref_img_folder': 'original', 'weights_path': 'weights/weights_DISTS_finetuned.pt'}\n"
     ]
    }
   ],
   "source": [
    "# Read config and data for testing\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, default=\"config/test.cfg\", help=\"path to data config file\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=1000, help=\"size of each image batch\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args)\n",
    "config = parse_config(args.config)\n",
    "print(config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# read data\n",
    "dataset_dir = config['dataset_dir']\n",
    "label_file = config['label_file']\n",
    "dist_img_folder = config['dist_img_folder']\n",
    "testset = Dataset(data_dir=dataset_dir, label_file=label_file, dist_folder=dist_img_folder)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size)\n",
    "\n",
    "X1, X2, Y, mask = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STSIM-1 test: 0.8157561768297956\n",
      "STSIM-2 test: 0.8517013571296325\n"
     ]
    }
   ],
   "source": [
    "# Testing STSIM-1 and STSIM-2\n",
    "from metrics.STSIM import *\n",
    "X1 = X1.to(device).double()\n",
    "X2 = X2.to(device).double()\n",
    "Y = Y.to(device).double()\n",
    "mask = mask.to(device).double()\n",
    "m_g = Metric(sp3Filters, device=device)\n",
    "pred = m_g.STSIM(X1, X2)\n",
    "print(\"STSIM-1 test:\", evaluation(pred, Y, mask)) # 0.8158\n",
    "\n",
    "pred = m_g.STSIM2(X1, X2)\n",
    "print(\"STSIM-2 test:\", evaluation(pred, Y, mask))  # 0.8517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model with saved weights\n",
    "saved_weights_path = 'weights/weights_STSIM_mode1_finetuned.pt'\n",
    "mode = 1\n",
    "model = STSIM_M([X1_train.shape[1], 10],mode,device).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(saved_weights_path))\n",
    "pred = []\n",
    "pred.append(model(X1,X2))\n",
    "pred = torch.cat(pred, dim=0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STSIM_M test: 0.970938747683695\n"
     ]
    }
   ],
   "source": [
    "print(\"STSIM_M test:\", evaluation(pred, Y, mask))  #0.970938747683695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
