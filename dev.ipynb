{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from test import evaluation\n",
    "from test import PearsonCoeff\n",
    "from utils.dataset import Dataset\n",
    "from utils.parse_config import parse_config\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='config/train_STSIM.cfg')\n",
      "{'gpus': '0', 'num_workers': '0', 'model': 'STSIM', 'dataset_dir': 'dataset/jana2012/', 'label_file': 'label.xlsx', 'train_img_folder': 'train', 'valid_img_folder': 'train', 'ref_img_folder': 'original', 'weights_path': 'weights/STSIM/', 'epochs': '1000', 'train_batch_size': '1000', 'valid_batch_size': '1000', 'checkpoint_interval': '25', 'evaluation_interval': '50'}\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, default=\"config/train_STSIM.cfg\", help=\"path to data config file\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args)\n",
    "config = parse_config(args.config)\n",
    "print(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if not os.path.isdir(config['weights_path']):\n",
    "    os.mkdir(config['weights_path'])\n",
    "\n",
    "# read training data\n",
    "dataset_dir = config['dataset_dir']\n",
    "label_file = config['label_file']\n",
    "dist_img_folder = config['train_img_folder']\n",
    "train_batch_size = int(config['train_batch_size'])\n",
    "trainset = Dataset(data_dir=dataset_dir, label_file=label_file, dist_folder=dist_img_folder)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# read validation data\n",
    "dataset_dir = config['dataset_dir']\n",
    "dist_img_folder = config['valid_img_folder']\n",
    "valid_batch_size = int(config['valid_batch_size'])\n",
    "validset = Dataset(data_dir=dataset_dir, label_file=label_file, dist_folder=dist_img_folder)\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=valid_batch_size)\n",
    "\n",
    "epochs = int(config['epochs'])\n",
    "evaluation_interval = int(config['evaluation_interval'])\n",
    "checkpoint_interval = int(config['checkpoint_interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iter 0 : -0.4727785392293161\n",
      "validation iter 0 : 0.7674194513769742\n",
      "training iter 25 : -0.9364448604712491\n",
      "training iter 50 : -0.9465968989969985\n",
      "validation iter 50 : 0.9468765310028425\n",
      "training iter 75 : -0.9529661097362881\n",
      "training iter 100 : -0.9600361427655347\n",
      "validation iter 100 : 0.9603249009879116\n",
      "training iter 125 : -0.966575100866053\n",
      "training iter 150 : -0.971195776177751\n",
      "validation iter 150 : 0.9713498867943622\n",
      "training iter 175 : -0.9747435491563895\n",
      "training iter 200 : -0.9781039231214879\n",
      "validation iter 200 : 0.9782355418456247\n",
      "training iter 225 : -0.9810774603628811\n",
      "training iter 250 : -0.98320349723983\n",
      "validation iter 250 : 0.9832752576498688\n",
      "training iter 275 : -0.9847703021071144\n",
      "training iter 300 : -0.9860148876338238\n",
      "validation iter 300 : 0.9860599614202215\n",
      "training iter 325 : -0.987048191176593\n",
      "training iter 350 : -0.9879119681187791\n",
      "validation iter 350 : 0.9879436010630073\n",
      "training iter 375 : -0.988647793621395\n",
      "training iter 400 : -0.9892889219596992\n",
      "validation iter 400 : 0.9893129692884448\n",
      "training iter 425 : -0.9898604648407779\n",
      "training iter 450 : -0.9903836426490586\n",
      "validation iter 450 : 0.9904038247953031\n",
      "training iter 475 : -0.9908755999689263\n",
      "training iter 500 : -0.9913477361731091\n",
      "validation iter 500 : 0.9913663086359794\n",
      "training iter 525 : -0.9900996553322287\n",
      "training iter 550 : -0.9919920042473453\n",
      "validation iter 550 : 0.992083026249962\n",
      "training iter 575 : -0.9925165143452418\n",
      "training iter 600 : -0.9929185283414554\n",
      "validation iter 600 : 0.9929346211594965\n",
      "training iter 625 : -0.9923236337324388\n",
      "training iter 650 : -0.9931151208390437\n",
      "validation iter 650 : 0.9930045338159775\n",
      "training iter 675 : -0.9936039645581822\n",
      "training iter 700 : -0.9940269755028458\n",
      "validation iter 700 : 0.9939938032379152\n",
      "training iter 725 : -0.994193599827871\n",
      "training iter 750 : -0.9943506075662434\n",
      "validation iter 750 : 0.9941101124130551\n",
      "training iter 775 : -0.9945645304598651\n",
      "training iter 800 : -0.994434054253747\n",
      "validation iter 800 : 0.9946609914280797\n",
      "training iter 825 : -0.9947989356306319\n",
      "training iter 850 : -0.994859429195673\n",
      "validation iter 850 : 0.9947249541213333\n",
      "training iter 875 : -0.9950309644534345\n",
      "training iter 900 : -0.9944413291180613\n",
      "validation iter 900 : 0.9946277019297153\n",
      "training iter 925 : -0.9951293935522034\n",
      "training iter 950 : -0.9945162274791632\n",
      "validation iter 950 : 0.9949733362753591\n",
      "training iter 975 : -0.9952071568927581\n"
     ]
    }
   ],
   "source": [
    "if config['model'] == 'STSIM':\n",
    "    # prepare data\n",
    "    X1_train, X2_train, Y_train, mask_train = next(iter(train_loader))\n",
    "    X1_valid, X2_valid, Y_valid, mask_valid = next(iter(valid_loader))\n",
    "\n",
    "    from steerable.sp3Filters import sp3Filters\n",
    "    from metrics.STSIM import *\n",
    "    m = Metric(sp3Filters, device)\n",
    "    # STSIM-M features\n",
    "    X1_train = m.STSIM_M(X1_train.double().to(device))\n",
    "    X2_train = m.STSIM_M(X2_train.double().to(device))\n",
    "    X1_valid = m.STSIM_M(X1_valid.double().to(device))\n",
    "    X2_valid = m.STSIM_M(X2_valid.double().to(device))\n",
    "    Y_train = Y_train.to(device)\n",
    "    Y_valid = Y_valid.to(device)\n",
    "    mask_train = mask_train.to(device)\n",
    "    mask_valid = mask_valid.to(device)\n",
    "\n",
    "    # learnable parameters\n",
    "    model = STSIM_M([X1_train.shape[1], 10], device).double().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        pred = model(X1_train, X2_train)\n",
    "        loss = -PearsonCoeff(pred, Y_train, mask_train)  # min neg ==> max\n",
    "        #loss = torch.mean((pred - Y_train) ** 2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 25 == 0:\n",
    "            print('training iter ' + str(i) + ' :', loss.item())\n",
    "        if i % evaluation_interval == 0:    # validation\n",
    "            pred = model(X1_valid, X2_valid)\n",
    "            val = evaluation(pred, Y_valid, mask_valid)\n",
    "            print('validation iter ' + str(i) + ' :', val)\n",
    "        if i % checkpoint_interval == 0:    # save weights\n",
    "            torch.save(model.state_dict(), os.path.join(config['weights_path'], 'epoch_' + str(i).zfill(4) + '.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from steerable.sp3Filters import sp3Filters\n",
    "from utils.dataset import Dataset\n",
    "from utils.parse_config import parse_config\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def PearsonCoeff(X, Y, mask):\n",
    "    '''\n",
    "    Args:\n",
    "        X: [N, 1] neural prediction for one batch, or [N] some other metric's output\n",
    "        Y: [N] label\n",
    "        mask: [N] indicator of correspondent class, e.g. [0,0,1,1] ,means first two samples are class 0, the rest two samples are class 1\n",
    "    Returns: Borda's rule of pearson coeff between X&Y, the same as using numpy.corrcoef()\n",
    "    '''\n",
    "    coeff = 0\n",
    "    N = set(mask.detach().cpu().numpy())\n",
    "    X = X.squeeze(-1)\n",
    "    for i in N:\n",
    "        X1 = X[mask == i].double()\n",
    "        X1 = X1 - X1.mean()\n",
    "        X2 = Y[mask == i].double()\n",
    "        X2 = X2 - X2.mean()\n",
    "\n",
    "        nom = torch.dot(X1, X2)\n",
    "        denom = torch.sqrt(torch.sum(X1 ** 2) * torch.sum(X2 ** 2))\n",
    "\n",
    "        coeff += torch.abs(nom / (denom + 1e-10))\n",
    "    return coeff / len(N)\n",
    "\n",
    "def evaluation(pred, Y, mask):\n",
    "    return PearsonCoeff(pred, Y, mask).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1000, config='config/test.cfg')\n",
      "{'gpus': '0', 'num_workers': '0', 'model': 'STSIM', 'dataset_dir': 'dataset/jana2012/', 'label_file': 'label.xlsx', 'dist_img_folder': 'test', 'ref_img_folder': 'original', 'weights_path': 'weights/weights_DISTS_finetuned.pt'}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, default=\"config/test.cfg\", help=\"path to data config file\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=1000, help=\"size of each image batch\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "print(args)\n",
    "config = parse_config(args.config)\n",
    "print(config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# read data\n",
    "dataset_dir = config['dataset_dir']\n",
    "label_file = config['label_file']\n",
    "dist_img_folder = config['dist_img_folder']\n",
    "testset = Dataset(data_dir=dataset_dir, label_file=label_file, dist_folder=dist_img_folder)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size)\n",
    "\n",
    "X1, X2, Y, mask = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STSIM-1 test: 0.8157561768297956\n",
      "STSIM-2 test: 0.8517013571296325\n"
     ]
    }
   ],
   "source": [
    "from metrics.STSIM import *\n",
    "X1 = X1.to(device).double()\n",
    "X2 = X2.to(device).double()\n",
    "Y = Y.to(device).double()\n",
    "mask = mask.to(device).double()\n",
    "m_g = Metric(sp3Filters, device=device)\n",
    "pred = m_g.STSIM(X1, X2)\n",
    "print(\"STSIM-1 test:\", evaluation(pred, Y, mask)) # 0.8158\n",
    "\n",
    "pred = m_g.STSIM2(X1, X2)\n",
    "print(\"STSIM-2 test:\", evaluation(pred, Y, mask))  # 0.8517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'weights/STSIM/epoch_0975.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STSIM_M(torch.nn.Module):\n",
    "    def __init__(self, dim ,device=None):\n",
    "        '''\n",
    "        Args:\n",
    "            mode: regression, STSIM-M\n",
    "            weights_path:\n",
    "        '''\n",
    "        super(STSIM_M, self).__init__()\n",
    "        self.linear = nn.Linear(dim[0], dim[1])\n",
    "        self.device = torch.device('cpu') if device is None else device\n",
    "\n",
    "    def forward(self, X1, X2):\n",
    "        '''\n",
    "        Args:\n",
    "            X1:\n",
    "            X2:\n",
    "        Returns:\n",
    "        '''\n",
    "        if len(X1.shape)==4:\n",
    "            # the input are raw images, extract STSIM-M features\n",
    "            from steerable.sp3Filters import sp3Filters\n",
    "            m = Metric(sp3Filters, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                X1 = m.STSIM_M(X1)\n",
    "                X2 = m.STSIM_M(X2)\n",
    "        #pred = F.sigmoid(self.linear(torch.abs(X1-X2)))\t# [N, dim]\n",
    "        pred = self.linear(torch.abs(X1-X2))\t# [N, dim]\n",
    "        pred = torch.bmm(pred.unsqueeze(1), pred.unsqueeze(-1)).squeeze(-1)\t# inner-prod\n",
    "        return torch.sqrt(pred)\t# [N, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = STSIM_M(dim = [82,10],weights_path=config['weights_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(weights_path))\n",
    "pred = []\n",
    "pred.append(model(X1,X2))\n",
    "pred = torch.cat(pred, dim=0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STSIM_M test: 0.9555486244612739\n"
     ]
    }
   ],
   "source": [
    "print(\"STSIM_M test:\", evaluation(pred, Y, mask))  #0.9555486244612739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
